{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbor Experiment\n",
    "\n",
    "This notebook will use the dataset prepared by another notebook [prepare_dataset](prepare_dataset.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's install some dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: /Users/leung.tsz.kit/Desktop/work/code/test/github_repos/ann_search_sample/nearest_neighbor/.venv/bin/pip: bad interpreter: /Users/leung.tsz.kit/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/bin/python3.9: no such file or directory\n"
     ]
    }
   ],
   "source": [
    "!pip install -q numpy pandas scikit-learn nagisa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you need to follow the installation guide to install FastText [here](https://fasttext.cc/docs/en/support.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fasttext.util\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import nagisa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And set some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"./tmp/converted_company_ds.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Load the dataset\n",
    "\n",
    "We will load the prepared csv file, this csv included a field `concat_name`, which is the concatenated name + postal code + address.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>法人名</th>\n",
       "      <th>郵便番号</th>\n",
       "      <th>本社所在地</th>\n",
       "      <th>concat_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2346868</th>\n",
       "      <td>島内建設株式会社</td>\n",
       "      <td>519-0142</td>\n",
       "      <td>三重県亀山市天神4丁目11番10号</td>\n",
       "      <td>島内建設株式会社 519-0142 三重県亀山市天神4丁目11番10号</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867786</th>\n",
       "      <td>林塗装株式会社</td>\n",
       "      <td>635-0062</td>\n",
       "      <td>奈良県大和高田市礒野南町5番32号</td>\n",
       "      <td>林塗装株式会社 635-0062 奈良県大和高田市礒野南町5番32号</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010599</th>\n",
       "      <td>佛教勝友会</td>\n",
       "      <td>737-0032</td>\n",
       "      <td>広島県呉市本町7番4号</td>\n",
       "      <td>佛教勝友会 737-0032 広島県呉市本町7番4号</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5040750</th>\n",
       "      <td>株式会社メイクス</td>\n",
       "      <td>565-0854</td>\n",
       "      <td>大阪府吹田市桃山台3丁目22番2号</td>\n",
       "      <td>株式会社メイクス 565-0854 大阪府吹田市桃山台3丁目22番2号</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912237</th>\n",
       "      <td>株式会社勝</td>\n",
       "      <td>154-0001</td>\n",
       "      <td>東京都世田谷区池尻4丁目10番1-E201号</td>\n",
       "      <td>株式会社勝 154-0001 東京都世田谷区池尻4丁目10番1-E201号</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              法人名      郵便番号                   本社所在地  \\\n",
       "2346868  島内建設株式会社  519-0142       三重県亀山市天神4丁目11番10号   \n",
       "2867786   林塗装株式会社  635-0062       奈良県大和高田市礒野南町5番32号   \n",
       "3010599     佛教勝友会  737-0032             広島県呉市本町7番4号   \n",
       "5040750  株式会社メイクス  565-0854       大阪府吹田市桃山台3丁目22番2号   \n",
       "3912237     株式会社勝  154-0001  東京都世田谷区池尻4丁目10番1-E201号   \n",
       "\n",
       "                                   concat_name  \n",
       "2346868    島内建設株式会社 519-0142 三重県亀山市天神4丁目11番10号  \n",
       "2867786     林塗装株式会社 635-0062 奈良県大和高田市礒野南町5番32号  \n",
       "3010599             佛教勝友会 737-0032 広島県呉市本町7番4号  \n",
       "5040750    株式会社メイクス 565-0854 大阪府吹田市桃山台3丁目22番2号  \n",
       "3912237  株式会社勝 154-0001 東京都世田谷区池尻4丁目10番1-E201号  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_path, dtype=str)\n",
    "# Fill NA again because empty string is read as NA anyway\n",
    "df = df.fillna(\"\")\n",
    "df.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, we will convert `concat_name` into vectors representation and use `法人名` as the display value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[\"concat_name\"]\n",
    "company_names = df[\"法人名\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save some memory.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## Exp. A:  Nearest neighbor model (with fastText Embedding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Load the Embedding converter\n",
    "\n",
    "We will use the [word embedding](https://fasttext.cc/docs/en/crawl-vectors.html) from fast Text. This embedding vectors will be used during fitting & inference to convert the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the word embeddings (if not existed)\n",
    "fasttext.util.download_model('ja', if_exists='ignore')\n",
    "# Load the pre-trained model\n",
    "ft = fasttext.load_model('cc.ja.300.bin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look how a piece of words are converted into vectors.\n",
    "\n",
    "The word vectors we downloaded is for Japanese, with dimension 300. You can reduce the dimension as described [here](https://fasttext.cc/docs/en/crawl-vectors.html#adapt-the-dimension).\n",
    "\n",
    "Also, you can download other languages in the same page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector shape:  (300,)\n",
      "[ 0.00068098 -0.0003277   0.00181239 -0.00983721 -0.00108764  0.00500185\n",
      " -0.00861101 -0.00744833 -0.00053406  0.00237652]\n"
     ]
    }
   ],
   "source": [
    "test_vec = ft.get_word_vector(\"有限会社PIA 東京都千代田区内神田 2-11-4 トーハンビル5階\")\n",
    "print(\"Vector shape: \", test_vec.shape)\n",
    "print(test_vec[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The util even provides method to do a nearest neighbor search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9167303442955017, 'こんばんは'),\n",
       " (0.9152794480323792, 'こんにちわ'),\n",
       " (0.8549860715866089, 'こんばんわ'),\n",
       " (0.7946215271949768, 'はじめまして'),\n",
       " (0.7212551236152649, 'おはよう'),\n",
       " (0.6740288734436035, 'どーも'),\n",
       " (0.6339334845542908, 'こんち'),\n",
       " (0.6219503283500671, 'どうも'),\n",
       " (0.6091426014900208, 'みなさん'),\n",
       " (0.5997785925865173, 'ゃにゃちは')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_nearest_neighbors('こんにちは')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit a Nearest Neighbor model later, we have to convert the feature into vectors so the model can understand.\n",
    "\n",
    "Below conversion will take a few minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init a numpy array with all zeros in the shape of (samples, word vectors)\n",
    "features_vec = np.zeros((features.shape[0], ft.get_dimension()))\n",
    "\n",
    "for i, sentence in enumerate(features):\n",
    "    features_vec[i] = ft.get_word_vector(sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5167760,)\n",
      "(5167760, 300)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "# (sample, vector dim)\n",
    "print(features_vec.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Nearest Neighbor Model\n",
    "\n",
    "Now we have the features prepared, we can start fitting a nearest neighbor model via scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "knn.fit(features_vec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the model prepared, let's try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text =  FUJITEX株式会社フジテックス 169-0072 東京都新宿区大久保3-8-2-13 \n",
      "\n",
      "Distance = 0.2020 , Index =  1393808  , target text:  株式会社ひかり薬局 169-0072 東京都新宿区大久保2丁目6番17号\n",
      "Distance = 0.2194 , Index =  1396185  , target text:  株式会社クロス 169-0072 東京都新宿区大久保1丁目6番6号市川荘\n",
      "Distance = 0.2199 , Index =  1565715  , target text:  株式会社フジテックス 169-0072 東京都新宿区大久保3丁目8番2号住友不動産新宿ガーデンタワー\n",
      "Distance = 0.2202 , Index =  1481297  , target text:  株式会社C-mind 169-0072 東京都新宿区大久保2丁目5番23号\n",
      "Distance = 0.2228 , Index =  1050400  , target text:  株式会社大洲 169-0072 東京都新宿区大久保1丁目16番24号楽園会館203号\n",
      "========================================================================================================================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\n",
    "    # # 林塗装株式会社 635-0062 奈良県大和高田市礒野南町5番32号\n",
    "    # \"林塗装株式会社 635-0062 奈良県大和高田市礒野南町5番32号\",\n",
    "    # # 有限会社PIA 東京都千代田区内神田 2-11-4 トーハンビル5階\n",
    "    # \"有限 P I A 東京都千代田区内神田 2-11-4\",\n",
    "\n",
    "    \"FUJITEX株式会社フジテックス 169-0072 東京都新宿区大久保3-8-2-13\",\n",
    "]\n",
    "# Convert into vector features.\n",
    "input_features = [ft.get_word_vector(x) for x in input_texts]\n",
    "\n",
    "# get the result\n",
    "D, N = knn.kneighbors(input_features, n_neighbors=5, return_distance=True)\n",
    "\n",
    "for input_text, distances, neighbors in zip(input_texts, D, N):\n",
    "    print(\"Input text = \", input_text[:200], \"\\n\")\n",
    "    for dist, neighbor_idx in zip(distances, neighbors):\n",
    "        print(f\"Distance = {dist:0.4f}\", \", Index = \", neighbor_idx, \" , target text: \", features[neighbor_idx])\n",
    "    print(\"=\"*200)\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above example, seems the model cannot search the name if the input missed or provide wrong info.\n",
    "\n",
    "I suspect the reason is that the text embedding we used are focusing in the context too much. But we only need to focus at the \"wordings\" in this situation.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Prepare JP tokenizer\n",
    "\n",
    "For other experiments afterwards, we will need our own JP tokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "釧路検察審査会 北海道釧路市柏木町 4-7 \n",
      "['釧路', '検察', '審査', '会', '北海道', '釧路', '市', '柏木町', '4', '7']\n",
      "伊達簡易裁判所 北海道伊達市末永町 47-10 \n",
      "['伊達', '簡易', '裁判', '所', '北海道', '伊達', '市', '末永', '町', '4', '7', '1', '0']\n"
     ]
    }
   ],
   "source": [
    "# Takes in a document, filtering out particles, punctuation, and verb endings\n",
    "def tokenize_jp(text):\n",
    "    # text = text.\n",
    "    doc = nagisa.filter(text, filter_postags=['空白', '助詞', '補助記号', '助動詞'])\n",
    "    return doc.words\n",
    "\n",
    "print(features[0])\n",
    "print(tokenize_jp(features[0]))\n",
    "print(features[1])\n",
    "print(tokenize_jp(features[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Try with other text vectors - TF-IDF\n",
    "\n",
    "By the above observation, let's try TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(tokenizer=tokenize_jp, ngram_range=(1,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fit the TFIDF model with the text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leung.tsz.kit/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000, 40089)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features_tfidf = vec.fit_transform(features)\n",
    "print(features.shape)\n",
    "print(features_tfidf.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can train the nearest neighbor model with this vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=10)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_tfidf = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "knn_tfidf.fit(features_tfidf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the model ready, let's give it a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text =   P IA 式 ト 東京都千代田区内 2-1-4 6階 \n",
      "\n",
      "Distance = 0.6345 , Index =  375  , target text:  アンフィニィ株式会社 東京都千代田区内神田 2-13-14 \n",
      "Distance = 0.6903 , Index =  3  , target text:  有限会社PIA 東京都千代田区内神田 2-11-4 トーハンビル5階\n",
      "Distance = 0.8372 , Index =  253  , target text:  デュリソルアジア株式会社 東京都千代田区永田町 2-9-8 \n",
      "Distance = 0.8401 , Index =  162  , target text:  株式会社ラクーン 東京都千代田区外神田 5-2-10 \n",
      "Distance = 0.8405 , Index =  146  , target text:  有限会社マイセン 東京都千代田区神田小川町 1-11 \n",
      "========================================================================================================================================================================================================\n",
      "\n",
      "Input text =  鹿高神社三重県名張市安部1942 \n",
      "\n",
      "Distance = 0.4454 , Index =  2  , target text:  鹿高神社 三重県名張市安部田 1942 \n",
      "Distance = 0.8310 , Index =  334  , target text:  八阪神社 三重県四日市市赤堀 2-9-8 \n",
      "Distance = 0.9092 , Index =  447  , target text:  株式会社北清緑建 宮崎県都城市太郎坊町 942-1 \n",
      "Distance = 0.9140 , Index =  646  , target text:  一般社団法人天原会 福岡県春日市大土居 1-94 \n",
      "Distance = 0.9161 , Index =  31  , target text:  株式会社パネルヤ 千葉県印旛郡栄町安食台 3-19-4 \n",
      "========================================================================================================================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\n",
    "    # 有限会社PIA 東京都千代田区内神田 2-11-4 トーハンビル5階\n",
    "    \" P IA 式 ト 東京都千代田区内 2-1-4 6階\",\n",
    "    # 鹿高神社 三重県名張市安部田 1942 \n",
    "    \"鹿高神社三重県名張市安部1942\",\n",
    "]\n",
    "input_features = vec.transform(input_texts)\n",
    "\n",
    "# get the result\n",
    "D, N = knn_tfidf.kneighbors(input_features, n_neighbors=5, return_distance=True)\n",
    "\n",
    "for input_text, distances, neighbors in zip(input_texts, D, N):\n",
    "    print(\"Input text = \", input_text[:200], \"\\n\")\n",
    "    for dist, neighbor_idx in zip(distances, neighbors):\n",
    "        print(f\"Distance = {dist:0.4f}\", \", Index = \", neighbor_idx, \" , target text: \", features[neighbor_idx])\n",
    "    print(\"=\"*200)\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, we can see the second example  \"鹿高神社三重県名張市安部1942\", it is strange that cannot match just due to extra space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## Try with Bag of words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Have to use JP tokenizer because default one does not know how to split words\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize_jp, ngram_range=(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leung.tsz.kit/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Fit the bag of word model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m features_bow \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39;49mfit_transform(features)\n",
      "File \u001b[0;32m~/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1380\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1381\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1382\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m             )\n\u001b[1;32m   1386\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[1;32m   1390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[1;32m   1391\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1275\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[1;32m   1274\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[0;32m-> 1275\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[1;32m   1276\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:113\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    111\u001b[0m     doc \u001b[39m=\u001b[39m preprocessor(doc)\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     doc \u001b[39m=\u001b[39m tokenizer(doc)\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m ngrams \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[39mif\u001b[39;00m stop_words \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m, in \u001b[0;36mtokenize_jp\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize_jp\u001b[39m(text):\n\u001b[1;32m      3\u001b[0m     \u001b[39m# text = text.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     doc \u001b[39m=\u001b[39m nagisa\u001b[39m.\u001b[39;49mfilter(text, filter_postags\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39m空白\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m助詞\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m補助記号\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m助動詞\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m doc\u001b[39m.\u001b[39mwords\n",
      "File \u001b[0;32m~/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/nagisa/tagger.py:202\u001b[0m, in \u001b[0;36mTagger.filter\u001b[0;34m(self, text, lower, filter_postags)\u001b[0m\n\u001b[1;32m    200\u001b[0m postags \u001b[39m=\u001b[39m []\n\u001b[1;32m    201\u001b[0m tokens  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtagging(text, lower)\n\u001b[0;32m--> 202\u001b[0m \u001b[39mfor\u001b[39;00m word, postag \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(tokens\u001b[39m.\u001b[39mwords, tokens\u001b[39m.\u001b[39;49mpostags):\n\u001b[1;32m    203\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m postag \u001b[39min\u001b[39;00m filter_postags:\n\u001b[1;32m    204\u001b[0m         words\u001b[39m.\u001b[39mappend(word)\n",
      "File \u001b[0;32m~/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/nagisa/tagger.py:256\u001b[0m, in \u001b[0;36mTagger._Token.postags\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpostags\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__postags \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__postags \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__postagging(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwords, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__lower)\n\u001b[1;32m    257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__postags\n",
      "File \u001b[0;32m~/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/nagisa/tagger.py:131\u001b[0m, in \u001b[0;36mTagger._postagging\u001b[0;34m(self, words, lower)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m                 w2p\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pos2id[\u001b[39mu\u001b[39m\u001b[39m'\u001b[39m\u001b[39m名詞\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 131\u001b[0m     w2p \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39;49m(w2p))\n\u001b[1;32m    132\u001b[0m     tids\u001b[39m.\u001b[39mappend(w2p)\n\u001b[1;32m    134\u001b[0m X \u001b[39m=\u001b[39m [cids, wids, tids]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the bag of word model\n",
    "features_bow = vectorizer.fit_transform(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how vectorizer split the address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "株式会社新潟丸和運輸 新潟県新潟市東区海老ケ瀬字長田 502-1 \n",
      "['株式', '会社', '新潟', '丸和', '運輸', '新潟', '県', '新潟', '市', '東', '区', '海老ケ瀬', '字', '長田', '5', '0', '2', '1', '株式 会社', '会社 新潟', '新潟 丸和', '丸和 運輸', '運輸 新潟', '新潟 県', '県 新潟', '新潟 市', '市 東', '東 区', '区 海老ケ瀬', '海老ケ瀬 字', '字 長田', '長田 5', '5 0', '0 2', '2 1', '株式 会社 新潟', '会社 新潟 丸和', '新潟 丸和 運輸', '丸和 運輸 新潟', '運輸 新潟 県', '新潟 県 新潟', '県 新潟 市', '新潟 市 東', '市 東 区', '東 区 海老ケ瀬', '区 海老ケ瀬 字', '海老ケ瀬 字 長田', '字 長田 5', '長田 5 0', '5 0 2', '0 2 1', '株式 会社 新潟 丸和', '会社 新潟 丸和 運輸', '新潟 丸和 運輸 新潟', '丸和 運輸 新潟 県', '運輸 新潟 県 新潟', '新潟 県 新潟 市', '県 新潟 市 東', '新潟 市 東 区', '市 東 区 海老ケ瀬', '東 区 海老ケ瀬 字', '区 海老ケ瀬 字 長田', '海老ケ瀬 字 長田 5', '字 長田 5 0', '長田 5 0 2', '5 0 2 1', '株式 会社 新潟 丸和 運輸', '会社 新潟 丸和 運輸 新潟', '新潟 丸和 運輸 新潟 県', '丸和 運輸 新潟 県 新潟', '運輸 新潟 県 新潟 市', '新潟 県 新潟 市 東', '県 新潟 市 東 区', '新潟 市 東 区 海老ケ瀬', '市 東 区 海老ケ瀬 字', '東 区 海老ケ瀬 字 長田', '区 海老ケ瀬 字 長田 5', '海老ケ瀬 字 長田 5 0', '字 長田 5 0 2', '長田 5 0 2 1']\n"
     ]
    }
   ],
   "source": [
    "analyze_bow = vectorizer.build_analyzer()\n",
    "print(features[0])\n",
    "print(analyze_bow(features[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can look at the terms stored in the model directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '0 0', '0 0 0', ..., '𣳾 新 商事', '𣳾 新 商事 北海道', '𣳾 新 商事 北海道 札幌'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_bow = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "knn_bow.fit(features_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text =  高神社三重県名張市安部1942 \n",
      "\n",
      "Distance = 0.2546 , Index =  2  , target text:  鹿高神社 三重県名張市安部田 1942 \n",
      "Distance = 0.7226 , Index =  334  , target text:  八阪神社 三重県四日市市赤堀 2-9-8 \n",
      "Distance = 0.7750 , Index =  871  , target text:  有限会社マチノ 三重県四日市市久保田 2-14-4 \n",
      "Distance = 0.7767 , Index =  447  , target text:  株式会社北清緑建 宮崎県都城市太郎坊町 942-1 \n",
      "Distance = 0.7778 , Index =  443  , target text:  有限会社イエンプロダクション 三重県四日市市小生町 229-222 \n",
      "========================================================================================================================================================================================================\n",
      "\n",
      "Input text =  三重県名張市1942 \n",
      "\n",
      "Distance = 0.3494 , Index =  2  , target text:  鹿高神社 三重県名張市安部田 1942 \n",
      "Distance = 0.7545 , Index =  871  , target text:  有限会社マチノ 三重県四日市市久保田 2-14-4 \n",
      "Distance = 0.7564 , Index =  447  , target text:  株式会社北清緑建 宮崎県都城市太郎坊町 942-1 \n",
      "Distance = 0.7575 , Index =  443  , target text:  有限会社イエンプロダクション 三重県四日市市小生町 229-222 \n",
      "Distance = 0.7685 , Index =  587  , target text:  合資会社田村製瓦工場 愛媛県今治市菊間町浜甲 1949 \n",
      "========================================================================================================================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\n",
    "    # 有限会社PIA 東京都千代田区内神田 2-11-4 トーハンビル5階\n",
    "    # \"PIA\",\n",
    "    # \"有限 P I A 式 ト 東京都千代田区内 2-1-4 56階\",\n",
    "\n",
    "    # 鹿高神社 三重県名張市安部田 1942 \n",
    "    \"高神社三重県名張市安部1942\",\n",
    "    \"三重県名張市1942\",\n",
    "\n",
    "]\n",
    "input_features = vectorizer.transform(input_texts)\n",
    "\n",
    "# get the result\n",
    "D, N = knn_bow.kneighbors(input_features, n_neighbors=5, return_distance=True)\n",
    "\n",
    "for input_text, distances, neighbors in zip(input_texts, D, N):\n",
    "    print(\"Input text = \", input_text[:200], \"\\n\")\n",
    "    for dist, neighbor_idx in zip(distances, neighbors):\n",
    "        print(f\"Distance = {dist:0.4f}\", \", Index = \", neighbor_idx, \" , target text: \", features[neighbor_idx])\n",
    "    print(\"=\"*200)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
