{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbor Experiment\n",
    "\n",
    "This notebook will use the dataset prepared by another notebook [prepare_dataset](prepare_dataset.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fasttext.util\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import nagisa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Load the dataset\n",
    "\n",
    "We will load the prepared csv file, this csv included a field `concat_name`, which is the concatenated name + postal code + address.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./features_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>法人名</th>\n",
       "      <th>concat_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>547367</th>\n",
       "      <td>有限会社笠幡</td>\n",
       "      <td>有限会社笠幡 埼玉県鶴ヶ島市大字鶴ヶ丘 733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988461</th>\n",
       "      <td>株式会社ライフエイト</td>\n",
       "      <td>株式会社ライフエイト 東京都新宿区歌舞伎町 2-8-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663394</th>\n",
       "      <td>大正埠頭作業株式会社</td>\n",
       "      <td>大正埠頭作業株式会社 大阪府大阪市大正区小林西 1-25-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279765</th>\n",
       "      <td>有限会社中山商事</td>\n",
       "      <td>有限会社中山商事 東京都文京区本郷 1-20-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516069</th>\n",
       "      <td>合資会社ホルモン栄養研究所洋酒部</td>\n",
       "      <td>合資会社ホルモン栄養研究所洋酒部 大阪府大阪市天王寺区東平野町一丁目 27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      法人名                             concat_name\n",
       "547367             有限会社笠幡                有限会社笠幡 埼玉県鶴ヶ島市大字鶴ヶ丘 733 \n",
       "3988461        株式会社ライフエイト            株式会社ライフエイト 東京都新宿区歌舞伎町 2-8-3 \n",
       "3663394        大正埠頭作業株式会社        大正埠頭作業株式会社 大阪府大阪市大正区小林西 1-25-13 \n",
       "4279765          有限会社中山商事               有限会社中山商事 東京都文京区本郷 1-20-3 \n",
       "2516069  合資会社ホルモン栄養研究所洋酒部  合資会社ホルモン栄養研究所洋酒部 大阪府大阪市天王寺区東平野町一丁目 27 "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[\"concat_name\"]\n",
    "company_names = df[\"法人名\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save some memory.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Prepare JP tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "釧路検察審査会 北海道釧路市柏木町 4-7 \n",
      "['釧路', '検察', '審査', '会', '北海道', '釧路', '市', '柏木町', '4', '7']\n",
      "伊達簡易裁判所 北海道伊達市末永町 47-10 \n",
      "['伊達', '簡易', '裁判', '所', '北海道', '伊達', '市', '末永', '町', '4', '7', '1', '0']\n"
     ]
    }
   ],
   "source": [
    "# Takes in a document, filtering out particles, punctuation, and verb endings\n",
    "def tokenize_jp(text):\n",
    "    # text = text.\n",
    "    doc = nagisa.filter(text, filter_postags=['空白', '助詞', '補助記号', '助動詞'])\n",
    "    return doc.words\n",
    "\n",
    "print(features[0])\n",
    "print(tokenize_jp(features[0]))\n",
    "print(features[1])\n",
    "print(tokenize_jp(features[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Load the Embedding converter\n",
    "\n",
    "We will use the same embedding from fast Text. This embedding will be used during inference to convert the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "ft = fasttext.load_model('cc.ja.300.bin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test its feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00068098, -0.0003277 ,  0.00181239, -0.00983721, -0.00108764,\n",
       "        0.00500185, -0.00861101, -0.00744833, -0.00053406,  0.00237652],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_word_vector(\"有限会社PIA 東京都千代田区内神田 2-11-4 トーハンビル5階\")[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## Exp. A:  Nearest neighbor model (with fastText Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "knn.fit(features_vec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the model prepared, let's try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text =  有限 P I A 東京都千代田区内神田 2-11-4 \n",
      "\n",
      "Distance = 0.3833 , Index =  375  , target text:  アンフィニィ株式会社 東京都千代田区内神田 2-13-14 \n",
      "Distance = 0.4221 , Index =  756  , target text:  オーストラリア政府観光局 東京都千代田区永田町 2-11-1 山王パークタワー12階\n",
      "Distance = 0.4265 , Index =  406  , target text:  合同会社ブリーズ 兵庫県神戸市東灘区本山中町 4-10-20 \n",
      "Distance = 0.4268 , Index =  185  , target text:  社会復帰サポート美祢株式会社 東京都渋谷区神宮前 1-5-1 \n",
      "Distance = 0.4320 , Index =  285  , target text:  株式会社ライフイノベーション 神奈川県横浜市港北区新横浜 3-13-6 新横浜葉山第3ビル3階\n",
      "========================================================================================================================================================================================================\n",
      "\n",
      "Input text =  三重県名張市安部田 \n",
      "\n",
      "Distance = 0.5078 , Index =  2  , target text:  鹿高神社 三重県名張市安部田 1942 \n",
      "Distance = 0.5209 , Index =  752  , target text:  マークスター有限会社 福岡県福岡市早良区干隈 4-25-1-404 \n",
      "Distance = 0.5559 , Index =  641  , target text:  氷川神社 埼玉県上尾市大字平塚 1514 \n",
      "Distance = 0.5587 , Index =  104  , target text:  合資会社三共商會 山口県下関市大字関後地村 1032 \n",
      "Distance = 0.5622 , Index =  160  , target text:  桂昌庵 島根県雲南市吉田町吉田 2367 \n",
      "========================================================================================================================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\n",
    "    # 有限会社PIA 東京都千代田区内神田 2-11-4 トーハンビル5階\n",
    "    \"有限 P I A 東京都千代田区内神田 2-11-4\",\n",
    "    # 鹿高神社 三重県名張市安部田 1942 \n",
    "    \"三重県名張市安部田\",\n",
    "]\n",
    "input_features = [ft.get_word_vector(x) for x in input_texts]\n",
    "\n",
    "# get the result\n",
    "D, N = knn.kneighbors(input_features, n_neighbors=5, return_distance=True)\n",
    "\n",
    "for input_text, distances, neighbors in zip(input_texts, D, N):\n",
    "    print(\"Input text = \", input_text[:200], \"\\n\")\n",
    "    for dist, neighbor_idx in zip(distances, neighbors):\n",
    "        print(f\"Distance = {dist:0.4f}\", \", Index = \", neighbor_idx, \" , target text: \", features[neighbor_idx])\n",
    "    print(\"=\"*200)\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above example, seems the model cannot search the name if the input missed or provide wrong info.\n",
    "\n",
    "I suspect the reason is that the text embedding we used are focusing in the context too much. But we only need to focus at the \"wordings\" in this situation.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Try with other text vectors - TF-IDF\n",
    "\n",
    "By the above observation, let's try TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(tokenizer=tokenize_jp, ngram_range=(1,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fit the TFIDF model with the text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leung.tsz.kit/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000, 40089)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features_tfidf = vec.fit_transform(features)\n",
    "print(features.shape)\n",
    "print(features_tfidf.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can train the nearest neighbor model with this vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=10)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_tfidf = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "knn_tfidf.fit(features_tfidf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the model ready, let's give it a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text =   P IA 式 ト 東京都千代田区内 2-1-4 6階 \n",
      "\n",
      "Distance = 0.6345 , Index =  375  , target text:  アンフィニィ株式会社 東京都千代田区内神田 2-13-14 \n",
      "Distance = 0.6903 , Index =  3  , target text:  有限会社PIA 東京都千代田区内神田 2-11-4 トーハンビル5階\n",
      "Distance = 0.8372 , Index =  253  , target text:  デュリソルアジア株式会社 東京都千代田区永田町 2-9-8 \n",
      "Distance = 0.8401 , Index =  162  , target text:  株式会社ラクーン 東京都千代田区外神田 5-2-10 \n",
      "Distance = 0.8405 , Index =  146  , target text:  有限会社マイセン 東京都千代田区神田小川町 1-11 \n",
      "========================================================================================================================================================================================================\n",
      "\n",
      "Input text =  鹿高神社三重県名張市安部1942 \n",
      "\n",
      "Distance = 0.4454 , Index =  2  , target text:  鹿高神社 三重県名張市安部田 1942 \n",
      "Distance = 0.8310 , Index =  334  , target text:  八阪神社 三重県四日市市赤堀 2-9-8 \n",
      "Distance = 0.9092 , Index =  447  , target text:  株式会社北清緑建 宮崎県都城市太郎坊町 942-1 \n",
      "Distance = 0.9140 , Index =  646  , target text:  一般社団法人天原会 福岡県春日市大土居 1-94 \n",
      "Distance = 0.9161 , Index =  31  , target text:  株式会社パネルヤ 千葉県印旛郡栄町安食台 3-19-4 \n",
      "========================================================================================================================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\n",
    "    # 有限会社PIA 東京都千代田区内神田 2-11-4 トーハンビル5階\n",
    "    \" P IA 式 ト 東京都千代田区内 2-1-4 6階\",\n",
    "    # 鹿高神社 三重県名張市安部田 1942 \n",
    "    \"鹿高神社三重県名張市安部1942\",\n",
    "]\n",
    "input_features = vec.transform(input_texts)\n",
    "\n",
    "# get the result\n",
    "D, N = knn_tfidf.kneighbors(input_features, n_neighbors=5, return_distance=True)\n",
    "\n",
    "for input_text, distances, neighbors in zip(input_texts, D, N):\n",
    "    print(\"Input text = \", input_text[:200], \"\\n\")\n",
    "    for dist, neighbor_idx in zip(distances, neighbors):\n",
    "        print(f\"Distance = {dist:0.4f}\", \", Index = \", neighbor_idx, \" , target text: \", features[neighbor_idx])\n",
    "    print(\"=\"*200)\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, we can see the second example  \"鹿高神社三重県名張市安部1942\", it is strange that cannot match just due to extra space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## Try with Bag of words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Have to use JP tokenizer because default one does not know how to split words\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize_jp, ngram_range=(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leung.tsz.kit/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Fit the bag of word model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m features_bow \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39;49mfit_transform(features)\n",
      "File \u001b[0;32m~/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1380\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1381\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1382\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m             )\n\u001b[1;32m   1386\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[1;32m   1390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[1;32m   1391\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1275\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[1;32m   1274\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[0;32m-> 1275\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[1;32m   1276\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:113\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    111\u001b[0m     doc \u001b[39m=\u001b[39m preprocessor(doc)\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     doc \u001b[39m=\u001b[39m tokenizer(doc)\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m ngrams \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[39mif\u001b[39;00m stop_words \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m, in \u001b[0;36mtokenize_jp\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize_jp\u001b[39m(text):\n\u001b[1;32m      3\u001b[0m     \u001b[39m# text = text.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     doc \u001b[39m=\u001b[39m nagisa\u001b[39m.\u001b[39;49mfilter(text, filter_postags\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39m空白\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m助詞\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m補助記号\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m助動詞\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m doc\u001b[39m.\u001b[39mwords\n",
      "File \u001b[0;32m~/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/nagisa/tagger.py:202\u001b[0m, in \u001b[0;36mTagger.filter\u001b[0;34m(self, text, lower, filter_postags)\u001b[0m\n\u001b[1;32m    200\u001b[0m postags \u001b[39m=\u001b[39m []\n\u001b[1;32m    201\u001b[0m tokens  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtagging(text, lower)\n\u001b[0;32m--> 202\u001b[0m \u001b[39mfor\u001b[39;00m word, postag \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(tokens\u001b[39m.\u001b[39mwords, tokens\u001b[39m.\u001b[39;49mpostags):\n\u001b[1;32m    203\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m postag \u001b[39min\u001b[39;00m filter_postags:\n\u001b[1;32m    204\u001b[0m         words\u001b[39m.\u001b[39mappend(word)\n",
      "File \u001b[0;32m~/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/nagisa/tagger.py:256\u001b[0m, in \u001b[0;36mTagger._Token.postags\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpostags\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__postags \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__postags \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__postagging(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwords, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__lower)\n\u001b[1;32m    257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__postags\n",
      "File \u001b[0;32m~/Desktop/work/code/test/github_repos/ann_search_sample/annoy/.venv/lib/python3.9/site-packages/nagisa/tagger.py:131\u001b[0m, in \u001b[0;36mTagger._postagging\u001b[0;34m(self, words, lower)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m                 w2p\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pos2id[\u001b[39mu\u001b[39m\u001b[39m'\u001b[39m\u001b[39m名詞\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 131\u001b[0m     w2p \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39;49m(w2p))\n\u001b[1;32m    132\u001b[0m     tids\u001b[39m.\u001b[39mappend(w2p)\n\u001b[1;32m    134\u001b[0m X \u001b[39m=\u001b[39m [cids, wids, tids]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the bag of word model\n",
    "features_bow = vectorizer.fit_transform(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how vectorizer split the address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "株式会社新潟丸和運輸 新潟県新潟市東区海老ケ瀬字長田 502-1 \n",
      "['株式', '会社', '新潟', '丸和', '運輸', '新潟', '県', '新潟', '市', '東', '区', '海老ケ瀬', '字', '長田', '5', '0', '2', '1', '株式 会社', '会社 新潟', '新潟 丸和', '丸和 運輸', '運輸 新潟', '新潟 県', '県 新潟', '新潟 市', '市 東', '東 区', '区 海老ケ瀬', '海老ケ瀬 字', '字 長田', '長田 5', '5 0', '0 2', '2 1', '株式 会社 新潟', '会社 新潟 丸和', '新潟 丸和 運輸', '丸和 運輸 新潟', '運輸 新潟 県', '新潟 県 新潟', '県 新潟 市', '新潟 市 東', '市 東 区', '東 区 海老ケ瀬', '区 海老ケ瀬 字', '海老ケ瀬 字 長田', '字 長田 5', '長田 5 0', '5 0 2', '0 2 1', '株式 会社 新潟 丸和', '会社 新潟 丸和 運輸', '新潟 丸和 運輸 新潟', '丸和 運輸 新潟 県', '運輸 新潟 県 新潟', '新潟 県 新潟 市', '県 新潟 市 東', '新潟 市 東 区', '市 東 区 海老ケ瀬', '東 区 海老ケ瀬 字', '区 海老ケ瀬 字 長田', '海老ケ瀬 字 長田 5', '字 長田 5 0', '長田 5 0 2', '5 0 2 1', '株式 会社 新潟 丸和 運輸', '会社 新潟 丸和 運輸 新潟', '新潟 丸和 運輸 新潟 県', '丸和 運輸 新潟 県 新潟', '運輸 新潟 県 新潟 市', '新潟 県 新潟 市 東', '県 新潟 市 東 区', '新潟 市 東 区 海老ケ瀬', '市 東 区 海老ケ瀬 字', '東 区 海老ケ瀬 字 長田', '区 海老ケ瀬 字 長田 5', '海老ケ瀬 字 長田 5 0', '字 長田 5 0 2', '長田 5 0 2 1']\n"
     ]
    }
   ],
   "source": [
    "analyze_bow = vectorizer.build_analyzer()\n",
    "print(features[0])\n",
    "print(analyze_bow(features[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can look at the terms stored in the model directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '0 0', '0 0 0', ..., '𣳾 新 商事', '𣳾 新 商事 北海道', '𣳾 新 商事 北海道 札幌'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_bow = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "knn_bow.fit(features_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text =  高神社三重県名張市安部1942 \n",
      "\n",
      "Distance = 0.2546 , Index =  2  , target text:  鹿高神社 三重県名張市安部田 1942 \n",
      "Distance = 0.7226 , Index =  334  , target text:  八阪神社 三重県四日市市赤堀 2-9-8 \n",
      "Distance = 0.7750 , Index =  871  , target text:  有限会社マチノ 三重県四日市市久保田 2-14-4 \n",
      "Distance = 0.7767 , Index =  447  , target text:  株式会社北清緑建 宮崎県都城市太郎坊町 942-1 \n",
      "Distance = 0.7778 , Index =  443  , target text:  有限会社イエンプロダクション 三重県四日市市小生町 229-222 \n",
      "========================================================================================================================================================================================================\n",
      "\n",
      "Input text =  三重県名張市1942 \n",
      "\n",
      "Distance = 0.3494 , Index =  2  , target text:  鹿高神社 三重県名張市安部田 1942 \n",
      "Distance = 0.7545 , Index =  871  , target text:  有限会社マチノ 三重県四日市市久保田 2-14-4 \n",
      "Distance = 0.7564 , Index =  447  , target text:  株式会社北清緑建 宮崎県都城市太郎坊町 942-1 \n",
      "Distance = 0.7575 , Index =  443  , target text:  有限会社イエンプロダクション 三重県四日市市小生町 229-222 \n",
      "Distance = 0.7685 , Index =  587  , target text:  合資会社田村製瓦工場 愛媛県今治市菊間町浜甲 1949 \n",
      "========================================================================================================================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\n",
    "    # 有限会社PIA 東京都千代田区内神田 2-11-4 トーハンビル5階\n",
    "    # \"PIA\",\n",
    "    # \"有限 P I A 式 ト 東京都千代田区内 2-1-4 56階\",\n",
    "\n",
    "    # 鹿高神社 三重県名張市安部田 1942 \n",
    "    \"高神社三重県名張市安部1942\",\n",
    "    \"三重県名張市1942\",\n",
    "\n",
    "]\n",
    "input_features = vectorizer.transform(input_texts)\n",
    "\n",
    "# get the result\n",
    "D, N = knn_bow.kneighbors(input_features, n_neighbors=5, return_distance=True)\n",
    "\n",
    "for input_text, distances, neighbors in zip(input_texts, D, N):\n",
    "    print(\"Input text = \", input_text[:200], \"\\n\")\n",
    "    for dist, neighbor_idx in zip(distances, neighbors):\n",
    "        print(f\"Distance = {dist:0.4f}\", \", Index = \", neighbor_idx, \" , target text: \", features[neighbor_idx])\n",
    "    print(\"=\"*200)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
